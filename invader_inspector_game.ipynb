{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T03:55:01.388671Z",
     "start_time": "2020-11-14T03:55:00.840097Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cgd_utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Game Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T04:57:40.645590Z",
     "start_time": "2020-11-14T04:57:40.637474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Game constants\n",
    "num_evaders = 3\n",
    "num_exits = 9\n",
    "points_per_inspector = [3, 3, 3]\n",
    "num_inspectors = len(points_per_inspector)\n",
    "\n",
    "bounds = [0] + list(np.cumsum(points_per_inspector))\n",
    "inspector_ranges = [(bounds[i], bounds[i+1]) for i in range(num_inspectors)]\n",
    "\n",
    "# Check that each point has exactly one inspector.\n",
    "assert(sum(points_per_inspector) == num_exits)\n",
    "\n",
    "# Calculate game payoffs\n",
    "def calculate_expected_payoffs(evader_player_list, inspector_player_list):\n",
    "    '''Given lists of evader probabilities and inspector probabilities, compute expected payoffs'''\n",
    "    # Normalize each evader's probabilities to [0, 1].\n",
    "    normalized_evader_list = (\n",
    "        [evader_tensor / torch.norm(evader_tensor, 1) \n",
    "         for evader_tensor in evader_player_list])\n",
    "    \n",
    "    # Normalize each inspector's probabilities to [0,1].\n",
    "    normalized_inspector_list = (\n",
    "        [inspect_tensor / torch.norm(inspect_tensor, 1) \n",
    "         for inspect_tensor in inspector_player_list])\n",
    "    \n",
    "    inspector_probabilities = 1 - torch.cat(normalized_inspector_list)\n",
    "    \n",
    "    # Get evader expected payoffs in-order of evader, which is probability that\n",
    "    # evader choses a point, that the inspector does not (i.e. complement)\n",
    "    evader_payoffs = [-torch.dot(evader_tensor, inspector_probabilities) \n",
    "                      for evader_tensor in normalized_evader_list]\n",
    "    \n",
    "    # Define list of inspector payoffs\n",
    "    inspector_payoffs = [torch.tensor(0.) \n",
    "                         for _ in range(num_inspectors)]\n",
    "    \n",
    "    # For inspector, payoff is probability that evader and inspector both chose the same exit.\n",
    "    for evader_tensor in normalized_evader_list:\n",
    "        for i, ((start, stop), inspector_tensor) in (\n",
    "                enumerate(zip(inspector_ranges, normalized_inspector_list))):\n",
    "            \n",
    "            inspector_payoffs[i] += -torch.dot(inspector_tensor, evader_tensor[start: stop])\n",
    "            \n",
    "    return evader_payoffs, inspector_payoffs\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T04:59:28.728300Z",
     "start_time": "2020-11-14T04:59:26.680276Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],\n",
      "       grad_fn=<DivBackward0>), tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],\n",
      "       grad_fn=<DivBackward0>), tensor([0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111, 0.1111],\n",
      "       grad_fn=<DivBackward0>)]\n",
      "[tensor([0.3333, 0.3333, 0.3333], grad_fn=<DivBackward0>), tensor([0.3333, 0.3333, 0.3333], grad_fn=<DivBackward0>), tensor([0.3333, 0.3333, 0.3333], grad_fn=<DivBackward0>)]\n"
     ]
    }
   ],
   "source": [
    "num_iterations = 200\n",
    "learning_rates = [0.1] * (num_evaders + num_inspectors)\n",
    "\n",
    "# Define initial probability-ish tensors for evaders and invaders\n",
    "evader_player_list = [torch.tensor([1.] * num_exits, \n",
    "                                   requires_grad=True) \n",
    "                      for _ in range(num_evaders)]\n",
    "\n",
    "inspector_player_list = [torch.tensor([1.] * (num_points), \n",
    "                                      requires_grad=True) \n",
    "                          for num_points in points_per_inspector]\n",
    "\n",
    "for i in range(num_iterations):\n",
    "    evader_payoffs, inspector_payoffs = calculate_expected_payoffs(evader_player_list, inspector_player_list)\n",
    "    \n",
    "    updates, _ = cgd_utils.metamatrix_conjugate_gradient(\n",
    "        evader_payoffs + inspector_payoffs, \n",
    "        evader_player_list + inspector_player_list, \n",
    "        lr_list=learning_rates)\n",
    "    \n",
    "    \n",
    "    for player, update in zip(evader_player_list + inspector_player_list, updates):\n",
    "        player.data.add_(update)\n",
    "        \n",
    "normalized_evader_list = (\n",
    "        [evader_tensor / torch.norm(evader_tensor, 1) \n",
    "         for evader_tensor in evader_player_list])\n",
    "normalized_inspector_list = (\n",
    "        [inspect_tensor / torch.norm(inspect_tensor, 1) \n",
    "         for inspect_tensor in inspector_player_list])\n",
    "        \n",
    "print(normalized_evader_list)\n",
    "print(normalized_inspector_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
